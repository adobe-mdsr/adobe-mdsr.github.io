---
title: "Unsupervised Memorability Modeling from Tip-of-the-Tongue Retrieval Queries"
authors:
- Sree Bhattacharyya
- Yaman K. Singla
- Sudhir Yarram
- Somesh Singh
- Harini SI
- James Z. Wang

date: "2026-01-05T00:00:00Z"
doi: ""

publishDate: "2026-01-05T00:00:00Z"

publication_types: ["conference"]

publication: "IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2026)"
publication_short: "WACV"

abstract: "Visual memorability studies often depend on costly human annotations that capture only aggregate recall scores. We introduce ToT2MeM, a large-scale, unsupervised dataset that exploits Tip-of-the-Tongue (ToT) retrieval posts from Reddit to gather over 470k descriptive recall-content pairs, including an 82k video subset enriched with audio transcripts and OCR. Using these signals, we train ToT2MeM-Recall for descriptive recall generation and ToT2MeM-Retrieval for multimodal ToT retrieval, showing that fine-tuned vision-language models can surpass GPT-4o on free-form recall generation while supporting contrastive text-to-video retrieval. Our analysis highlights dataset breadth, qualitative behaviors, and remaining challenges such as semantic gaps, repetition, and hallucinated links, providing a new direction for scalable memorability modeling."

summary: ""

tags:
- Memorability
- Vision-Language
- Retrieval

featured: true



links:
  url_pdf: "https://arxiv.org/pdf/2511.20854"
  url_code: "https://github.com/sreebhattacharyya/web_scale_memorability"
  url_dataset: "https://huggingface.co/datasets/behavior-in-the-wild/web_scale_memorability"
  url_poster: ""
  url_project: "https://arxiv.org/abs/2511.20854"
  url_slides: ""
  url_source: ""
  url_video: ""

image:
  caption: "Overview of the ToT2MeM data pipeline and tasks."
  focal_point: "Smart"
  preview_only: false
  alt_text: "Pipeline diagram for web-scale memorability modeling."

projects: []
slides: ""
---

