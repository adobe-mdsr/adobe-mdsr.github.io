---
title: "Minimal: Mining Models for Universal Adversarial Triggers"
authors:
- Yaman Kumar Singla
- Swapnil Parekh
- Somesh Singh
- Changyou Chen
- Balaji Krishnamurthy
- Rajiv Ratn Shah

date: "2022-01-01T00:00:00Z"
doi: ""

publishDate: "2022-01-01T00:00:00Z"

publication_types: ["conference"]

publication: "AAAI"
publication_short: "AAAI"

abstract: "It is well known that natural language models are vulnerable to adversarial attacks, which are mostly input-specific in nature. Recently, it has been shown that there also exist input-agnostic attacks in NLP models, called universal adversarial triggers. However, existing methods to craft universal triggers are data intensive. They require large amounts of data samples to generate adversarial triggers, which are typically inaccessible by attackers. For instance, previous works take 3000 data samples per class for the SNLI dataset to generate adversarial triggers. In this paper, we present a novel data-free approach, MINIMAL, to mine input-agnostic adversarial triggers from models. Using the triggers produced with our data-free algorithm, we reduce the accuracy of Stanford Sentiment Treebank’s positive class from 93.6% to 9.6%. Similarly, for the Stanford Natural LanguageInference (SNLI), our single-word trigger reduces the accuracy of the entailment class from 90.95% to less than 0.6%. Despite being completely data-free, we get equivalent accuracy drops as data-dependent methods"

summary: "It is well known that natural language models are vulnerable to adversarial attacks, which are mostly input-specific in nature. Recently, it has been shown that there also exist input-agnostic attacks in NLP models, called universal adversarial triggers. However, existing methods to craft universal triggers are data intensive. They require large amounts of data samples to generate adversarial triggers, which are typically inaccessible by attackers. For instance, previous works take 3000 data samples per class for the SNLI dataset to generate adversarial triggers. In this paper, we present a novel data-free approach, MINIMAL, to mine input-agnostic adversarial triggers from models. Using the triggers produced with our data-free algorithm, we reduce the accuracy of Stanford Sentiment Treebank’s positive class from 93.6% to 9.6%. Similarly, for the Stanford Natural LanguageInference (SNLI), our single-word trigger reduces the accuracy of the entailment class from 90.95% to less than 0.6%. Despite being completely data-free, we get equivalent accuracy drops as data-dependent methods"

tags:
- Adversarial Triggers
- NLP
- Adversarial Robustness

featured: true



links:
url_pdf: "https://ojs.aaai.org/index.php/AAAI/article/view/21384"
url_code: "https://github.com/midas-research/data-free-uats"
url_dataset: ""
url_poster: ""
url_project: ""
url_slides: ""
url_source: ""
url_video: ""

image:
  caption: "Minimal: Mining Models for Universal Adversarial Triggers"
  focal_point: "Smart"
  preview_only: false
  alt_text: "Minimal: Mining Models for Universal Adversarial Triggers"

projects: []
slides: ""
---