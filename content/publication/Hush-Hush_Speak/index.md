---
title: "Hush-Hush Speak: Speech Reconstruction Using Silent Videos"
authors:
- Shashwat Uttam
- Yaman Kumar Singla
- Dhruva Sharawat
- Mansi Aggarwal
- Debanjan Mahata
- Rajiv Ratn Shah
- Amanda Stent

date: "2019-01-01T00:00:00Z"
doi: ""

publishDate: "2019-01-01T00:00:00Z"

publication_types: ["conference"]

publication: "InterSpeech"
publication_short: "InterSpeech"

abstract: "Speech Reconstruction is the task of recreation of speech using silent videos as input. In the literature, it is also referred to as lipreading. In this paper, we design an encoder-decoder architecture which takes silent videos as input and outputs an audio spectrogram of the reconstructed speech. The model, despite being a speaker-independent model, achieves comparable results on speech reconstruction to the current state-of-the-art speaker-dependent model. We also perform user studies to infer speech intelligibility. Additionally, we test the usability of the trained model using bilingual speech."

tags: ["Speechreconstruction", "Lipreading", "Encoder-decoder", "Audiospectrogram", "Userstudies"]
summary: ""

tags:
- Speechreconstruction
- Lipreading
- Encoderdecoder
- Audiospectrogram
- Userstudies
featured: false

links:
url_pdf: "https://www.isca-archive.org/interspeech_2019/uttam19_interspeech.html"
url_code: ""
url_dataset: ""
url_poster: ""
url_project: ""
url_slides: ""
url_source: ""
url_video: ""


projects: []
slides: ""
---
