---
title: "Robustness of Markov perfect equilibrium to model approximations in general-sum dynamic games"
authors:
- Subramanian J.
- Sinha A.
- Mahajan A.

date: "2021-01-01T00:00:00Z"
doi: ""

publishDate: "2021-01-01T00:00:00Z"

publication_types: ["conference"]

publication: "Indian Control Conference"
publication_short: "Indian"

abstract: "Dynamic games (also called stochastic games or Markov games) are an important class of games for modeling multi-agent interactions. In many situations, the dynamics and reward functions of the game are learnt from past data and are therefore approximate. In this paper, we study the robustness of Markov perfect equilibrium to approximations in reward and transition functions. Using approximation results from Markov decision processes, we show that the Markov perfect equilibrium of an approximate (or perturbed) game is always an approximate Markov perfect equilibrium of the original game. We provide explicit bounds on the approximation error in terms of three quantities: (i) the error in approximating the reward functions, (ii) the error in approximating the transition function, and (iii) a property of the value function of the MPE of the approximate game. The second and third quantities depend on the choice of metric on probability spaces. We also present coarser upper bounds which do not depend on the value function but only depend on the properties of the reward and transition functions of the approximate game. We illustrate the results via a numerical example."

summary: ""

tags:
- Markov
- Approximate
- Reward
- Functions
- Perfect
featured: false

links:
url_pdf: "https://ieeexplore.ieee.org/document/9703156"
url_code: ""
url_dataset: ""
url_poster: ""
url_project: ""
url_slides: ""
url_source: ""
url_video: ""


projects: []
slides: ""
---
